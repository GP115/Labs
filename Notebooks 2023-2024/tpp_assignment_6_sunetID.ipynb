{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#***Assignment 6: Taking the Pulse of the City: Who is impacted by air pollution in cities?***\n","This assignment is due on **2/15/2024**.\n","Change the name of your notebook to **tpp_assignment_6_sunetID.ipynb**\n","Share your completed notebook with the TAs akroo@stanford.edu & flora221@stanford.edu using the share banner at the top. If you are still having technical difficulties, email us before the deadline.\n"],"metadata":{"id":"rIXTM80rjn8h"}},{"cell_type":"markdown","source":["\n","###**INTRODUCTION TO THE ASSIGNMENT**\n","\n","This week’s assignment will get us thinking about environmental justice and aerosolized particulate matter pm2.5."],"metadata":{"id":"CGUfQQh1jfaL"}},{"cell_type":"markdown","source":["\n","###**DATA SETS**\n","The dataset that we will be using today comes from the PurpleAir Sensor Network. These are low cost sensors, purchased primarily by individuals to monitor air quality for their personal decision making. Some communities and cities have also invested in these monitors for better understanding health risks and supporting regulatory decision making.\n","\n","The dataset is over one year (2023), the sensors take measurements every few minutes, but the data has been down-sampled so that there are hourly data points that represent the average pm2.5 concentration measurement for that hour for that sensor.\n","\n","These sensors have been deployed globally, however for the context of this assignment, we will be focusing on their data from across the bay in Oakland, CA. We have focused on Oakland for a few reasons. Oakland is one of the most diverse cities in the bay area in just about every equity metrics. Because of this, Oakland has a complex and deeply historical relationship with racial justice, being the one of the centers of civil rights movements from its founding, through the civil rights movement of the ‘60s to today. One of the implications of this is that the City of Oakland Department of Transportation has done a tremendous amount of work to make census data available to the general public and researchers looking to take a data driven approach to analyzing inequities and public policy effects through their Geographic Equity Tookbox (OGET).\n","\n","\n","####**Units:**\n","Micrograms per cubic meter of air\n"],"metadata":{"id":"eYqM9If2jqHt"}},{"cell_type":"markdown","source":["\n","##**TOOLBOX**\n","All the Python functions and packages you will use in this assignment are in the toolbox for the course. We add new tools to the toolbox with each assignment as new ways of analyzing and visualizing data are introduced.\n","\n","https://colab.research.google.com/drive/1gQxlpnogdJzykfNqjIGO4VLMnHHhrvcC?usp=drive_link\n","\n"],"metadata":{"id":"-nTajzvYju01"}},{"cell_type":"markdown","source":["\n","##**THE LEARNING GOALS FOR THE WEEK**\n","where the course learning goals are in plain text, and the focus this week is in italics.\n","\n","\n","- Become familiar with the wide range of sensors available to study various components of the Earth system. These include sensors on satellites, aircraft, ground-based platforms, and deployed above or beneath the surface on land or water.\n","-  Become familiar with the basic physical principles (resolution, sampling, processing workflows, etc.) common to all sensors.\n","- Work with various sources of data, learning how to access, analyze, synthesize, and describe the data to quantify trends; think critically and creatively about how to project these trends into the future.\n"],"metadata":{"id":"Zu7HvJBwjxPO"}},{"cell_type":"markdown","source":["#### 1) **Install and Import Packages**: numpy, pandas, matplotlib (See Toolbox)"],"metadata":{"id":"PxhB-dhQmiWm"}},{"cell_type":"code","source":["#Download important packages to runtime\n","!pip install geojson rioxarray pykrige &> /dev/null\n","!pip install cartopy &> /dev/null"],"metadata":{"id":"8L2vx1ms2tzi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import geopandas as gpd\n","import geojson\n","import xarray as xr\n","import rioxarray\n","import cartopy.crs as ccrs\n","import cartopy.feature as cf\n","import shapely #useful in reshaping oget data\n","from shapely.geometry import mapping #useful\n","from pykrige.ok import OrdinaryKriging\n"],"metadata":{"id":"_z9O-7GI3H9Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2) **Getting the Data**: Loading the datasets\n","Ensure that you have reviewed the Introduction section, especially the discussion of the dataset. Take 3 minutes to familiarize yourself with Oakland’s Geographic Equity Toolbox (OGET) available at oakgis.maps.arcgis.com. One of our datasets comes from this site and includes all of the data categories that their visualization displays.\n"],"metadata":{"id":"_M1V9rZ0mjIP"}},{"cell_type":"code","source":["!git clone https://premonition.stanford.edu/taking-the-pulse-of-the-planet/OGET_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wfDHjtO_spYc","executionInfo":{"status":"ok","timestamp":1707399747542,"user_tz":-540,"elapsed":13827,"user":{"displayName":"Anne Kroo","userId":"01335049978940707144"}},"outputId":"8005722d-7599-423e-aa49-a640d221d3d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'OGET_data'...\n","warning: redirecting to https://premonition.stanford.edu/taking-the-pulse-of-the-planet/OGET_data.git/\n","remote: Enumerating objects: 44, done.\u001b[K\n","remote: Counting objects: 100% (8/8), done.\u001b[K\n","remote: Compressing objects: 100% (7/7), done.\u001b[K\n","remote: Total 44 (delta 2), reused 0 (delta 0), pack-reused 36\u001b[K\n","Receiving objects: 100% (44/44), 62.90 MiB | 16.56 MiB/s, done.\n","Resolving deltas: 100% (15/15), done.\n","Updating files: 100% (12/12), done.\n"]}]},{"cell_type":"code","source":["oak = gpd.read_file('OGET_data/Priority_Neighborhoods/Priority_Neighborhoods.shx')\n","oak['coords'] = oak['geometry'].apply(lambda x: x.representative_point().coords[:])\n","oak['coords'] = [coords[0] for coords in oak['coords']]\n","\n","df_oak = pd.read_csv('OGET_data/oak_2023.csv')\n","df_oak.rename(columns = {'datetime':'date'},inplace=True)\n","df_oak.drop(columns = 'Unnamed: 0',inplace=True)\n","df_oak = df_oak[df_oak.lon != df_oak.lon.max()]\n","df_oak = df_oak[df_oak.lon != df_oak.lon.max()]\n","\n","\n","#pull data\n","with open('OGET_data/GET_2021.geojson', 'r') as f:\n","  feature_collection = geojson.load(f)\n","#reformat data\n","all_features_data = pd.DataFrame()\n","for feature in feature_collection.features: # 117 features\n","  feature_geometry = feature.geometry # geojson geometry.\n","  feature_data = feature.properties # 92 columns!\n","  feature_id = feature_data['GEOID'] # they provide because it seems like a unique id\n","  feature_data_df = pd.DataFrame(feature_data, index=[feature_id])\n","  all_features_data = pd.concat([all_features_data, feature_data_df])\n"],"metadata":{"id":"dLZTv_yx5XbV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')\n","true_NW = (37.885367, -122.246913) #north west corner of neighborhood\n","true_SE = (37.849975, -122.214179) #south east corner of neighborhood\n","real_range = (true_NW[0]-true_SE[0], abs(true_NW[1]-true_SE[1])) #neighborhood range\n","\n","known_obj = oak.loc[[94]] #selecting known neighborhood\n","minx_k, miny_k, maxx_k, maxy_k = known_obj.total_bounds #getting the bounds of the neighborhood object\n","fake_range = (maxx_k-minx_k, maxy_k-miny_k) #What the dataset thinks its x y ranges are\n","known_obj_center = 0.5*(maxx_k+minx_k), 0.5*(maxy_k+miny_k) #the true center of the object\n","\n","scaling_factor = (real_range[0]/fake_range[0], real_range[1]/fake_range[1]) #how much do we need to zoom/unzoom\n","offset_factor = ((true_NW[1]+true_SE[1])/2)-known_obj_center[0]*scaling_factor[0],((true_NW[0]+true_SE[0])/2)-known_obj_center[1]*scaling_factor[1] #how much do we need to translate it\n","\n","#transform each object saving the centroid, geometry, and geoid for each object\n","for i in range(len(oak)):\n","  test_obj = oak.loc[[i]]\n","  test_obj=test_obj.scale(scaling_factor[0],scaling_factor[1],origin=(0,0))\n","  test_obj=test_obj.translate(+offset_factor[0], +offset_factor[1])\n","  if i == 0:\n","    oak_scaled = gpd.GeoDataFrame()\n","    oak_scaled['geometry'] = test_obj\n","    oak_scaled['coords'] = test_obj.centroid\n","    oak_scaled['geoid'] = oak.loc[[i]].GEOID\n","  else:\n","    temp = gpd.GeoDataFrame()\n","    temp['geometry'] = test_obj\n","    temp['coords'] = test_obj.centroid\n","    temp['geoid'] = oak.loc[[i]].GEOID\n","    oak_scaled = pd.concat([oak_scaled,temp])\n","minx_tot, miny_tot, maxx_tot, maxy_tot = oak_scaled.total_bounds\n","\n","#makes a geoseries containing the boarder of all of oakland without the neighborhood divisions, sometimes prettier\n","all_oak = gpd.geoseries.GeoSeries(shapely.ops.unary_union(oak_scaled.geometry.buffer(.0001)))\n"],"metadata":{"id":"mH5fQgmt5bDy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3) **Guided Data Analysis**\n","Each sensor value represents the value of PM2.5 concentration(particulates under 2.5um) at a single point in space. As such, a natural way of displaying this data is with a scatter plot where every location of a sensor is a dot and the color of the dot corresponds to the quantity of PM2.5 in the air."],"metadata":{"id":"yl_zNUyqmtGm"}},{"cell_type":"markdown","source":["##### **a)** Using the toolbox, make a scatter plot map of the data at a single time including the outlines of the neighborhoods of Oakland.\n","\n","Hint: break down this question into what you need to do to get the data at a single time and looking for a method to plot it in a scatter plot.\n"],"metadata":{"id":"yD8dM1BNm_z0"}},{"cell_type":"code","source":["# Your Scatter Plot Map Here"],"metadata":{"id":"3y7k3rM98TwQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **b)** What do you notice about the distribution of sensors? Why do you think it is not uniform across the city? Use the Oakland Geographic Equity Toolbox’s map and look up information about Purple Air sensors and Purple Air’s business model to inform your answer.\n","\n","https://www.oaklandca.gov/resources/oakdot-geographic-equity-toolbox"],"metadata":{"id":"MBREoiVYnGfI"}},{"cell_type":"markdown","source":["**Answer:**"],"metadata":{"id":"RjsNMBDO8dw2"}},{"cell_type":"markdown","source":["##### **c)** Make a scatter plot map of the average/mean pm2.5 concentration across the city\n","\n","We have included the code to take the average with respect to time of PM2.5 concentration. This means we are left with a single scatter plot map-like data frame in df_oak_avg\n"],"metadata":{"id":"K7hi1ETmnGvF"}},{"cell_type":"code","source":["df_oak_avg = df_oak.groupby(['lat','lon'], as_index=False).mean() #group data to have lat/lon/values divided up by date"],"metadata":{"id":"jL8z1V4ehEvI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Your Scatter Plot Map Here"],"metadata":{"id":"X-4b_HQy9HCQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In your plot from Part C, you may notice a lot of close together data points that give drastically different values. Because we are dealing with a dataset where the sensors are not actively managed by anyone, there can be a lot of variability in how they are set up and used. For example, all of the sensors included claim that they are outside, but there is no verification that the characteristics that the user has input are correct.\n"],"metadata":{"id":"xWf7o5tOowU5"}},{"cell_type":"markdown","source":["##### **d)** Using the toolbox filter out the average data in the extremes (below 25% and above 75%) and visualize it in a scatter plot map."],"metadata":{"id":"I_ENToz_nHGA"}},{"cell_type":"code","source":["# Your Data Filtering and Scatter Plot Map Here"],"metadata":{"id":"IPZy-5fn9RiX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In the last part we have reduced the impact of wonky sensors by eliminating spatial datapoints that are outliers, however outliers in these sensors exist between sensors (like in part d) as well as over time. On approach to mitigating the impact of these temporal outliers is to take the median instead of the mean of our data\n"],"metadata":{"id":"-3E9tvBkozMr"}},{"cell_type":"markdown","source":["##### **e)** Find the median pm2.5 concentrations at each sensor, filter the data to exclude wonky sensors (exclude extremes below 17% and above 95%). Plot it as a scatter plot map."],"metadata":{"id":"gb3sfYKGnHON"}},{"cell_type":"code","source":["# Your Median, Filtered Data, Scatter Plot Here"],"metadata":{"id":"4QtGW4_l9Yq8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **f)** Why might a mean or median be an appropriate measure for excluding outliers in this case? (2-5 sentances)\n"],"metadata":{"id":"Mf68obfvnHV_"}},{"cell_type":"markdown","source":["**Answer:**"],"metadata":{"id":"1Y5BFQAI9gU3"}},{"cell_type":"markdown","source":["------\n","\n","While these scatter plots help us describe the spatial distribution of pm2.5, there is still a substantial amount of variation in values between sensors that makes it hard to pick out and quantify spatial patterns. To address this, we will interpolate between the data points using a method used by air quality community called Kriging. Below is the function that we will use to do the interpolation, run the cell to create the function.\n"],"metadata":{"id":"i3eF2AK1o09j"}},{"cell_type":"code","source":["# Defines function that we will use to interpolate our air quality in 2D\n","def kriging(df,minx=-122.3506,maxx=-122.1126,miny=37.7086,maxy=37.8840,vari_mod = \"hole-effect\",cells=100):\n","  '''\n","  df: Data frame input should have four columns \"date\",\t\"value\",\t\"lat\",\t\"lon\"\n","  minx,...maxy: min and max values for final interpolated map\n","  Optional input: variogram model type. Options are linear, power, gaussian, spherical, exponential and hole-effect\n","  '''\n","  # Dropping all nan values for nan handling\n","  values = df['value']\n","  inds_active = ~np.isnan(values)\n","  xold = df['lon'][inds_active]\n","  yold = df['lat'][inds_active]\n","  zold = df['value'][inds_active]\n","\n","  # Create a 100 by 100 grid\n","  # Horizontal and vertical cell counts should be the same\n","  XX_pk_krig = np.linspace(minx, maxx, cells)\n","  YY_pk_krig = np.linspace(miny, maxy, cells)\n","\n","  # Generate ordinary kriging object\n","  OK = OrdinaryKriging(xold,yold,zold,variogram_model = vari_mod,verbose = False,enable_plotting = False,coordinates_type = \"euclidean\",exact_values=False)\n","\n","  # Evaluate the method on grid\n","  Z_pk_krig, sigma_squared_p_krig = OK.execute(\"grid\", XX_pk_krig, YY_pk_krig)\n","  correct_dims = ['lat', 'lon']\n","  correct_coords = {'lat': YY_pk_krig, 'lon': XX_pk_krig}\n","  correct_ds = xr.Dataset({'pm25': (correct_dims, Z_pk_krig)}, coords=correct_coords)\n","  return correct_ds"],"metadata":{"id":"12Y4yrvxiWPh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **g)** Using the toolbox, interpolate the median scatter plot map data from part E.\n"],"metadata":{"id":"uuDpgvtAnHfh"}},{"cell_type":"code","source":["# Your Interpoplated Median Plot Here"],"metadata":{"id":"316ndupe8J1U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **h)** Does this interpolated plot match what you expected? Are there areas of your interpolation that are more or less reliable? Why?"],"metadata":{"id":"0Qvajdx6nHmj"}},{"cell_type":"markdown","source":["**Answer:**"],"metadata":{"id":"kxs208x_8LfI"}},{"cell_type":"markdown","source":["------\n","Now that we have a gridded xarray dataset, we are finally in a position to start to answer our guiding question -- **Who is impacted by air pollution in cities?**\n","\n","By modifying the country_clipping function that went through and clipped all of the CO2 data to each country in Assignment 3, we can do the same thing for neighborhoods’ PM2.5 concentration. We get out a list containing the average pm2.5 concentration from our interpolated data for each neighborhood."],"metadata":{"id":"j0wzBq5Po5F0"}},{"cell_type":"markdown","source":["The code cell below lists all of the data categories in the Oakland Geographic Equity Toolbox, use their website to understand what each category means: https://www.oaklandca.gov/resources/oakdot-geographic-equity-toolbox.\n"],"metadata":{"id":"a_r0Y_jipBFD"}},{"cell_type":"code","source":["# Function for determining average pm25 over each neighborhood\n","# You do not need to understand this now, we will revisit it in the next assignment\n","# Should be familiar...\n","def neighbor_clipped_averages(dataset,bounds):\n","    '''Function that takes in dataset and gdf_boundaries and returns dataframe\n","    of average value of pm25 over that neighbor.\n","    Example of use: neighbor_vals = neighbor_clipped_averages(pm25_dataset, gdf_boundaries)'''\n","    neighbor_vals = pd.DataFrame(index=bounds.index)\n","    neighbor_vals.pm25 = 0\n","    neighbor_names = bounds.index\n","    for neighbor in neighbor_names:\n","      data_copy = dataset\n","      neighbor_boundary = bounds.loc[[neighbor]]\n","      data_copy.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\", inplace=True)\n","      data_copy.rio.write_crs(3857, inplace=True)\n","      data_clipped = data_copy.rio.clip(\n","          neighbor_boundary.geometry.apply(mapping),\n","          neighbor_boundary.crs,\n","          drop=True\n","      )\n","\n","      neighbor_vals.at[neighbor, 'pm25'] = float(data_clipped.pm25.mean(dim=['lon','lat']))\n","    return neighbor_vals"],"metadata":{"id":"kdk8uLsminaD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **i)** Plot neighborhood air quality as a function of a metric of your choice from the Oakland Geographic Equity categories."],"metadata":{"id":"IN6UhzCunHvs"}},{"cell_type":"code","source":["# this will return all the columns in our all features data\n","# Use this list to find a neighborhood metric you want to explore\n","# Ignore the first 9 options!\n","all_features_data.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H96_NYcb-deM","executionInfo":{"status":"ok","timestamp":1707386675918,"user_tz":-540,"elapsed":302,"user":{"displayName":"Anne Kroo","userId":"01335049978940707144"}},"outputId":"13988e29-1177-41ae-f5d1-4f8b489a04b1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['OBJECTID', 'NAME', 'FID_TL_201', 'TRACTCE', 'GEOID', 'NAME_1',\n","       'NAMELSAD', 'GEOID2_1', 'GEOGRAPHY', 'TOTAL_POP', 'TOTAL_POP_',\n","       'TOTAL_POP1', 'RACE_TOTAL', 'TOTAL_PO_1', 'TOTAL_PO_2', 'ONE_RACE',\n","       'ONE_RACE_W', 'BLACK_OR_A', 'AMINDIANAN', 'AMINDIAN_1', 'AMINDIAN_2',\n","       'AMINDIAN_3', 'AMINDIAN_4', 'ASIAN', 'ASIAN_INDI', 'ASIAN_CHIN',\n","       'ASIAN_FILI', 'ASIAN_JAPA', 'ASIAN_KORE', 'ASIAN_VIET', 'ASIAN_OTHE',\n","       'NATIVE_HI_', 'NATIVE_HI1', 'NATIVE_H_1', 'NATIVE_H_2', 'NATIVE_H_3',\n","       'OTHER', 'TWO_OR_MOR', 'WHITE_AND_', 'WHITE_AND1', 'WHITE_AN_1',\n","       'BLACK_AND_', 'HISPLAT_TO', 'HISPLAT__1', 'HISPLAT__2', 'HISPLAT__3',\n","       'HISPLAT__4', 'HISPLAT__5', 'HISPLAT_NO', 'HISPLAT_WH', 'HISPLAT_BL',\n","       'HISPLAT_AM', 'HISPLAT_AS', 'HISPLAT_NA', 'HISPLAT_OT', 'HISPLAT_2O',\n","       'HISPLAT__6', 'HISPLAT_2_', 'HISPLAT_HO', 'VOTERS_OVE', 'VOTERS_O_1',\n","       'VOTERS_O_2', 'SHAPE_LENG', 'SHAPE_AREA', 'SHAPE_AR_1', 'SHAPE_LEN',\n","       'TractNumb', 'Tract', 'Total_Popu', 'Final_Scor', 'Final_Sc_1',\n","       'Planning_A', 'Planning_1', 'Tract_1', 'Total_Po_3', 'Final_Sc_2',\n","       'PCT_POC', 'POC_Ratio', 'PCT_Low_In', 'Low_Income', 'PCT_Rent',\n","       'Rent_Ratio', 'PCT_Disabi', 'Disability', 'PCT_Senior', 'Seniors_Ra',\n","       'PCT_Single', 'Single_Par', 'PCT_Educat', 'Education', 'Planning_2',\n","       'name'],\n","      dtype='object')"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# TO USE: PASTE COLUMN NAME FROM ABOVE INTO YOUR_METRIC_HERE\n","metric = all_features_data.YOUR_METRIC_HERE # pull neighborhood metric for demographics\n","\n","#reformat some things. Don't worry about this\n","metric_dict = {all_features_data.GEOID[i]:metric[i] for i in range(len(all_features_data.GEOID))}\n","metric_list = []\n","geoids = oak_scaled.geoid\n","for x in geoids:\n","  metric_list.append(metric_dict[x])\n","\n","gdf = gpd.GeoDataFrame({'geometry': oak_scaled.geometry, 'values': metric_list},\n","    crs=\"EPSG:3857\")\n","gdf.set_geometry('geometry',inplace=True)"],"metadata":{"id":"qPRA3dxMi0EQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# YOUR Plot of Neighborhood Metric vs PM2.5 Here"],"metadata":{"id":"Yp9Fx4_A9ubH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["On this graph, we are interested in how closely the data fits a trend line, another way of saying this is *how correlated are these metrics*. We can calculate this numerically with the code below. A correlation coefficient is a number between -1 and 1 that represents how well a linear fit represents your data. A correlation of 1 would occur when your data falls perfectly along the line, -1 would mean it was perfectly on a line with the opposite slope to the trend line in comparison. With fewer data points, it's easier to make a line of best fit that closely approximates your data. This means we have to check to see if our correlation is statistically significant given the number of data points that we have as is shown in the second code block below."],"metadata":{"id":"T_DWXdDapGV7"}},{"cell_type":"markdown","source":["##### **j)** Test if this correlation between our independent and dependent variables is statistically significant by running the following code. Then discuss the implications and socio-political-economic reasons for your findings"],"metadata":{"id":"ds4jysbpnH4w"}},{"cell_type":"code","source":["pm25_values = YOUR_neighbor_vals_med.to_numpy().flatten() # THIS SHOULD BE THE OUTPUT OF THE neighbor_clipped_averages FUNCTION\n","metric_list = metric_list # this will correspond to the census metric defined earlier\n","r = np.corrcoef(pm25_values,y=metric_list)[0][1] # this gives us a numerical correlation betewen your metric and the air quality for all of the neighborhoods\n","r # Correlation coefficient"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sAfoBo2mjCzA","executionInfo":{"status":"ok","timestamp":1707398680577,"user_tz":-540,"elapsed":268,"user":{"displayName":"Anne Kroo","userId":"01335049978940707144"}},"outputId":"431928cc-06bf-4b0f-a540-ea6e03b530e2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.469173092207749"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["# TEST OF SIGNIFICANCE:\n","r >= 2/np.sqrt(len(pm25_values))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JRX-eJvZPQoY","executionInfo":{"status":"ok","timestamp":1707398684872,"user_tz":-540,"elapsed":347,"user":{"displayName":"Anne Kroo","userId":"01335049978940707144"}},"outputId":"671c610f-9499-4122-885d-6c6bb4cd0b62"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":52}]},{"cell_type":"markdown","source":["**Answer:**"],"metadata":{"id":"fU0ZcC6g97yz"}},{"cell_type":"markdown","source":["##**After Class**\n"],"metadata":{"id":"fc6R4bIVmzo5"}},{"cell_type":"markdown","source":["#### **a)** Discuss red-lining and the continued impact it has had on the population of Oakland from a health, economic, and social lens. Feel free to expand beyond this limited framing.  (~10 sentences)\n"],"metadata":{"id":"y4GS6YrWm56-"}},{"cell_type":"markdown","source":["**Answer:**"],"metadata":{"id":"hDKndtKM-Vl3"}},{"cell_type":"markdown","source":["#### **b)** What can be done and what is being done from a regulatory perspective to reduce the inequities that we have explored in this assignment?"],"metadata":{"id":"N6ewdoMSoCTW"}},{"cell_type":"markdown","source":["**Answer:**"],"metadata":{"id":"CmPK_QJ1-XkL"}},{"cell_type":"markdown","source":["#### **c)** Given your exploration of the data, pose a question that you think the data can answer."],"metadata":{"id":"sLMR9s-yoP-0"}},{"cell_type":"markdown","source":["**Answer:**"],"metadata":{"id":"_lhrA8To-Zcl"}},{"cell_type":"markdown","source":["#### **d)** Design a workflow (bullet points of steps for how you will answer the question)"],"metadata":{"id":"LE5nj8agoKmP"}},{"cell_type":"markdown","source":["**Answer:**\n","- List"],"metadata":{"id":"FLzQpKZl-cKc"}},{"cell_type":"markdown","source":["#### **e)** Answer your question with code"],"metadata":{"id":"Mssg_ps1oXIP"}},{"cell_type":"code","source":["# Your Code Here"],"metadata":{"id":"hOedA10u-ig3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **f)** Discuss the implications of your question."],"metadata":{"id":"pod6jFRAoa98"}},{"cell_type":"markdown","source":["**Answer:**"],"metadata":{"id":"iHYe6aLy-kEb"}}]}